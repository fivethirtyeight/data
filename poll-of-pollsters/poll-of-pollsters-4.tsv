"Please enter your information, and your polling organization's information. We won't publish your phone number and email address."		"In light of Tuesday results, did election polls do well this year at depicting the electorate's views?"			Why do you say that?	Which polling organizations were particularly successful at projecting Tuesday's results?	Which polling organizations were particularly unsuccessful at projecting Tuesday's results?	"Which types of polls (i.e. live phone, IVR, online panel) were particularly successful at projecting Tuesday's results?"	"Which types of polls (i.e. live phone, IVR, online panel) were particularly unsuccessful at projecting Tuesday's results?"	Please expand on your answers above -- why do you think particular polling organizations and types were particularly successful or unsuccessful?	"What implications, if any, do you see from election polling's 2014 performance for the future of election polling?"	"Now that we know roughly how many seats Republicans will control in 2015, how many seats do you expect Republicans will control in the Senate in 2017?"	Why?	How have your last 24 hours gone? (i.e. Did you watch returns come in? Did you hear from clients? How did you react? How much sleep did you get? etc.)Name	Polling Organization	Yes	No	Other (please specify)	Open-Ended Response	Open-Ended Response	Open-Ended Response	Open-Ended Response	Open-Ended Response	Open-Ended Response	Open-Ended Response	Open-Ended Response	Open-Ended Response	Open-Ended ResponseJohn Anzalone	Anzalone Liszt Grove Research	Yes			"Well, it really depends on what polls. I do think the averages that are compiled by FiveThirtyEight, HuffPost Pollster and Real Clear Politics are all helpful."	"To be honest, I have not checked to see."	"To be honest, I have not checked to see."	Live phone with cellphones are still the gold standard.	"I am curious to see how the New York Times YouGov online polls stacked up, but have not checked."	Unfortunately it is just too soon after the election for me to have spent any time seeing who was right and who was wrong. In the future you might give us respondents homework to do with an email before asking these types of questions.	Each year we as pollsters are going to have to work harder and tighten our procedures and methodology. You can conduct good pollling but you have to be willing to spend the money and time to do it right.	Who the fuck knows.	It doesn't matter how long you have been in this business; there are always going to be surprises each cycle. And I don't mean just at the end. No one thought six months ago Iowa and Colorado would be in play. It just takes one variable to change the whole equation.	It was a 24-hour enema.Micheline Blum	Blum & Weprin Associates													Gabriel Joseph	ccAdvertising		No		"They were off by more than they were correct. On all close races, most pollsters called it a toss-up or a one-point difference with a 5% error rate. You are almost always right when that happens. The North Carolina and Virginia races are good examples of how bad traditional pollsters were."	N/A	N/A	Mobile-phone based surveys.	"Online, push-button IVR."	Polls are only as accurate as the data they put in. Mobile-phone surveys provide a better image and reflection of the electorate. Everyone has one. Ignoring this universe of respondents is irresponsible.	"Pollsters will blame clients for not paying them enough to get it right. They will make more ""adjustments"" and tell clients that in 2016 they will be more accurate. Polling will be more prevalent and more expensive in 2016."	57	The top of the ticket will have coattails. Barack Obama will be a drag on the Democrats like George W. Bush was on Republicans in 2008.	We did well. I heard from a lot of clients. They are very happy that they chose to work with ccAdvertising and act on the survey responses we provided. It was a good night for our clients. It was a good night for ccAdvertising.Mark DiCamillo	Field Research Corporation (Field Poll)	Yes			They captured the trend toward the GOP in the final week. The movement was the story and the polls by and large got the story right.									Berwood Yost	Franklin & Marshall College	Yes			"In part, the answer depends on which polls, but overall the results didn't reveal any significant polling failure. The races that appeared close were close and most of the polls picked the right winners. A quick back-of-the-envelope look at some of the most-watched races does suggest a bit more of a Republican wave than state polling may have predicted."									Doug Kaplan	Gravis Marketing	Yes			"I think Gravis Marketing was ahead of the curve in 2014. We have the advantage of putting a poll in the field and getting results and releasing immediately. We caught the trend in Colorado, North Carolina and Maryland. We also saw the trend moving away in Kansas."							51	I have not spent a ton of time researching this. At the moment I would say 51. Florida will be a factor if Rubio runs because he will have to give up his Senate seat. Hillary could help in places like Pennsylvania and Wisconsin.	Matt Towery	InsiderAdvantage		No		We captured the trends but not the wave.						More online.	No idea		On TV all night and morning. Little sleep.Barbara Carvalho	Marist College	Yes			"Polls had a clear narrative that pointed to voters' concern about jobs, the economy, dissatisfaction with Washington and President Obama. And at the time many of the polls were taken, they showed close races when they were close and several organizations showed movement to the GOP from previous polls closer to Election Day. They also identified a narrowing gender gap, movement of indies [independents] to the GOP, and disaffection of Latinos in Colorado."					"In order to analyze the success of individual polling organizations, it's necessary to review how they were trending over time. Averaging snapshots or comparing last polls across organizations done at different times doesn't do this. Still looks like live-interviewer telephone polls with cellphones provide the best look and trend of the electorate even if they can't be the latest looks on the races. Again, field dates matter. Three-week field window can miss this. Models tout public in the wrong direction by calling polls that show different results from ""noisy"" average outliers, computing erroneous house effect based on it; and suggesting skew over three-week field period."	"Emphasis on average margin by models isn't helpful or necessarily informative. There was little value added to polling numbers by models. In fact, models tended to mute differences and trends based on averaging poll results... Des Moines Register poll in Iowa, Marist Poll in Kentucky, North Carolina, Georgia. Collapse of Greg Orman in Kansas two weeks out, [Colorado Sen. Mark] Udall's inability to attract Latinos, and the vanishing gender gap. All trends dismissed because they were not part of the average. Faster, cheaper, later, needs to be balanced with good science."		Let you know when we're three weeks outƒ just kidding!	"We do exit-poll analysis for media. Love Election Night: lots of numbers, analysis, and little sleepƒ it can't be beat."Brad Coker	"Mason-Dixon Polling & Research, Inc."	Yes			"Didn't get anything ""wrong."" I believe I predicted 54 GOP Senate (which is likely unless something unexpected happens in the Louisiana runoff)."	No opinion	No opinion	No opinion	No opinion	"Just don't believe in the ""my dick is bigger than yours"" debate. Everyone has good years and bad years."	None -- the zone will continue to be flooded.	I have no clue.	I'm just not thinking that far ahead. I have a life outside the business. I'm more interested in college football right now.	"All -- watch returns and talked to some clients. I generally spend more time communicating with friends and family -- who tie up my phone wanting to know ""What's going to happen?"" Slept seven hours -- 2 a.m. to 9 a.m. I had yogurt for breakfast."Seth Rosenthal	Merriman River Group													Patrick Murray	Monmouth University													Christopher Borick	Muhlenberg College	Yes			In general the polls did a good job of predicting the winners and losers on Tuesday but they appear to have generally underestimated the magnitude of Republican victories.	I haven't really had the chance to look at individual poll performance.				"Again, I really haven't looked that much at individual-level poll performance yet. Maybe after some sleep."	I'm not sure yet. On the aggregate we have seen polls overestimating GOP performance in 2012 and now overestimating Democratic performance in 2014. We will need to look pretty deeply at the underlying factors that may help explain these results. I expect to see some good panels at AAPOR [American Association for Public Opinion Research's annual meeting in May 2015] on this subject this spring.	48	"I think the expanded presidential electorate will benefit Democrats in many states and the GOP will be defending many more seats. I also think there is the possibility of Republican overreach in Congress over the next two years, thereby giving the Democrat nominee (in all likelihood Hillary Clinton) an advantage in the election cycle that may aid Democratic Senatorial candidates. It's a long way off but I think conditions will be more favorable to the Democrats in 2016."	Pretty good. Election nights are always exciting and don't include much sleep. Our poll performed pretty well so it looks like our methods have held up fairly well for another election cycle. On to 2016.Scott Keeter	Pew Research Center		No		"Many, if not most, Senate and gubernatorial polls underestimated the share of Republican vote in the electorate."						Hopefully we all learn from each election. The consistency of the errors this time may lead to a greater consideration of registered voter samples for election polling. I will be interested to see if RBS [Registration Based Sampling] polls performed better than RDD [Random Digit Dialing] polls this cycle. But it's also important to remember that polling biases are not always in the same direction. Two years ago the polls underestimated Democratic performance.			J. Ann Selzer	Selzer & Company													"I was part of the data team for Bloomberg Politics' first election-night show -- looking at exit polls as they were released, testing against past performance, helping tell stories about why things were happening the way they were. I did not get enough sleep."Don Levy	Siena College													Jay H. Leve	SurveyUSA													Darrel Rowland	The Columbus Dispatch	Yes			"We polled seven statewide races. The winners of all seven matched those who led our final poll, published Sunday. Even though many of the races were blowouts (unusual for Ohio), our poll came close to matching the actual totals. For example, the 31-percentage-point victory margin of Gov. John Kasich was just 3 points higher than the poll. In hard-to-call Supreme Court races, we had one exactly right and saw a 48-point landslide in the other; we had it at 50. The greatest variance was 7 points in the race for state treasurer; no others were more than 4. (FYI, the poll's MoE [margin of error] was +/- 3.3.) The Dispatch Poll has matched the actual winners of 35 of the 37 statewide races over the past decade in Ohio."		"In Ohio, Fox News had Gov. Kasich by only 15; CBS/NYT/YouGov had him by 19."			"Sorry, haven't had time to assess."	"Again, I haven't had time to assess in detail, but it seemed to me that races for U.S. Senate and governor that were projected as close were indeed close. I haven't had time to sort out who best foreshadowed actual winners and losers."			"Since I work for a newspaper, we wrote two page-one and two other cover stories for today, plus more inside... after numerous web updates throughout the evening yesterday not only on election results but on the sudden resignation of our state Democratic chairman. All in all, I got about five hours' sleep."
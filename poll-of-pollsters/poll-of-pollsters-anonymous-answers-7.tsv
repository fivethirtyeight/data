"The average presidential poll <a href=""http://fivethirtyeight.com/features/the-state-of-the-polls-2016/"" target=""_blank"">within the final 21 days of the election</a> has been off by 3.6 percentage points since 2000. Do you think that polling error will be better or worse this time?"		"<a href=""http://www.nytimes.com/interactive/2016/09/20/upshot/the-error-the-polling-world-rarely-talks-about.html"" target=""_blank"">The Upshot found</a> that different pollsters can get very different results with same data set. Did the results surprise you? Should pollsters be reporting a bigger margin of error or scrap the way they’re reporting it entirely?"	"How does the amount of <a href=""http://spotlight.ipsos-na.com/index.php/public-affairs/no-you-may-not-unskew-my-polls-a-refresher/"" target=""_blank"">talk of unskewing polls</a> from advocates and the media in 2016 compare to unskewing talk in 2012?"		"If you were given a blank check to poll the presidential race in any state, which state would you poll?"	Why do you say that?	"What grade would you give <a href=""http://projects.fivethirtyeight.com/pollster-ratings/"" target=""_blank"">FiveThirtyEight's pollster ratings</a>?"		Are media organizations commissioning and covering online polls in this race...		Are there any polls you would exclude if you were using polls to forecast the election?		"Should Gallup release <a href=""https://twitter.com/DavidLauter/status/784157638271655937"" target=""_blank"">its horse-race polls</a>? Why do you think it isn’t?"		"Do you think <a href=""http://fivethirtyeight.com/features/election-update-leave-the-la-times-poll-alone/"" target=""_blank"">the USC Dornsife/LA Times poll</a> approach of tracking the same group of respondents over time is a smart one?"		"A <a href=""http://www.nytimes.com/2016/10/06/us/politics/donald-trump-campaign.html"" target=""_blank"">recent New York Times article</a> suggested that private polls show different results than public polls. Is that usually the case? Any reason it would be this year?"	"What lessons have you learned from the primaries? For instance, what can be done to address <a href=""https://twitter.com/NateSilverFiveThirtyEight/status/736217950219309056"" target=""_blank"">the bias in polls in the Democratic primary</a> that depended on how many people in a state are black or Hispanic?"	What are the scheduled events and unscheduled possible events that you think are most likely to move the polls between now and Election Day?	"Do you think that in <a href=""http://fivethirtyeight.com/features/election-update-where-polls-and-demographics-disagree/"" target=""_blank"">the states where polls and demographic-based models diverge</a>, the polls or the demographics will prove to be closer to the result?"		Is there a demographic question you wish were routinely included in all polls that is currently left off?<br /><br /><br />		What is the one group of voters you wish we had more granular polling data about? Why?	Who do you expect will win the 2016 presidential election?		What percentage chance do you give each of these people to win the election?		Is Clinton more likely to...		"According to the national exit polls, what percentage of black voters will vote for"		How many seats do you expect Republicans will hold in the Senate in 2017 -- after the 2016 election? (They currently hold 54.)	How many seats do you expect Republicans will control in the House in 2017 -- after the 2016 election? (They currently hold 247.)	What question or questions would you want us to ask your fellow pollsters in future rounds of this poll?Response	Please explain your answer:	Open-Ended Response	Response	Please explain your answer:	Open-Ended Response	Open-Ended Response	Response	Why would you give it that grade?	Response	Why do you say that?	Response	"Please explain your answer, and say which polls you would include or exclude:"	Response	"Please explain your answer, and say why you think it isn't releasing them:"	Response	Why? Is it one you have used or will consider using in the future?	Open-Ended Response	Open-Ended Response	Open-Ended Response	Response	Why do you say that?	Response	"If yes, please specify and explain why."	Open-Ended Response	Response	Other (please specify)	Donald Trump	Hillary Clinton	Response	Why?	Donald Trump	Hillary Clinton	Open-Ended Response	Open-Ended Response	Open-Ended ResponseAbout the same		"Best case, what you describe above using the dangerous journalist shorthand ""margin of error"" is a THEORETICAL margin of *SAMPLING* error -- which applies only to sampling, and which does not even begin to measure all of the half a dozen other, more serious errors which are baked into every piece of opinion research."	Less		Arizona	"Because it would be more challenging than most states in terms of measuring turnout, especially among Hispanics."	A	Seems fair. I'd like pollsters to have the option to see what polls they were graded on -- which polls were being evaluated.	just the right amount	Need more insight though -- not just horse races.	No		No	I don't think they should be compelled to. They missed the mark in '12 and are trying to experiment with different models -- I dont think they are under an obligation to release their numbers until they are comfortable with their procedures.	No	"Panels can be problematic, and those problems get compounded by poor weighting schemes."	"I assume they match in some cases and differ in other cases, depending on the quality of the public poll and their methodology (list vs random-digit-dialing, etc)."	"For telephone polls, pay attention to differential response rates among landlines and cell phones."	"After the last week, I cannot even venture a guess."	Demographics		No		African Americans	Donald Trump		51	49	Lose the popular vote?	Reason unknown to any of us at this time.	20	80	52	239	"Completely different questions in every respect. And you should actually have a pollster help you write the questions; these questions in several cases are unanswerable, and the quality assurance on the poll was incomplete. I got repeat error messages and I test polls for a living."About the same	Same.	Did not surprise me.	Less	"The national polls have been so volatile with a lot of outlier polls, it feels like the whole idea of ""unskewing polls"" is less relevant this year."	Florida	"Multiple challenges; language, youth vote, turnout, down-ballot."	A	Because the grades offered make sense based on what I know about the pollsters.	just the right amount	"As they become more prevalent, the media will need to cover them more."	No		No	Gallup can do what it wants. There is no moral or ethical obligation to release it.	No		"I have done both (more private than public). I use exactly the same methods for both (turnout models, weights, etc.). But I think that in private polling, you're also likely to do more experimenting with alternative turnout models at the behest of your client, who then, in turn, may be biased toward, and even leak, the best-case scenarios from their perspective."	"I think modeling primary electorates is virtually impossible. Each cycle draws voters depending on the slate of candidates, or lack thereof. So, relying on past data to predict a future event seems wrong-headed."	"Clinton faints publicly again, Trump totally loses it and starts swearing during the 3rd debate!? Otherwise, a major terrorist attack is about it."	Demographics		No		"African Americans -- many segments within this cohort -- education level, origin, etc."	Hillary Clinton		10	90	Win by 10 or more points nationally?		10	90	49	240	Cost per complete online live automated etc. How much does it cost them to conduct a poll. Why do they release public polls? About the same	"I think turnout is a little uncertain. Republicans/Trump voters have been more likely to vote throughout the cycle but it appears to be shifting with Democrats/Clinton voters becoming more likely to vote. Uncertainly about turnout makes it difficult to ""predict"" the final margin."	Doesn't surprise me -- but the difference lies in analysis as much as margin of error.	Less		Georgia or Arizona	Democrats believe these states are in play and I'd like a closer look to understand why that is.	A-		too little		No	"I think pretty much everything should be included, and I appreciate your work to weight them."	No	Does it really matter at this point? 	No		"No, I don't think so."	"In Michigan, we underestimated turnout in the Democratic primary because there was no useful election history in the state for which to base Democratic turnout, and turnout in elections before Michigan were not useful in estimating Michigan."	"Debates obviously; current events, of course -- who knows..."	Demographics	"Particularly in states where voting blocs are hard to reach by phone (e.g., Nevada), where there's a history of polls missing."	No		African-Americans. It seems from the differences in Sanders/Clinton support during the primaries that there's a bit of a North/South split going on. Would be interesting to understand that better.	Hillary Clinton		5	95	Win by 10 or more points nationally?		4	96	50		How many times this year have you discarded a poll because the results seemed wildly incorrect?About the same		"I'd be in favor of scrapping it. It's widely misunderstood, and adds little value to readers' understanding of poll results."	Less		Nevada	"I want to have the money to do a fully bilingual poll, of which there are not nearly enough. Interactive-voice-response and internet polls can't really reach the population not really comfortable with their English skills or those that don't have landlines/reliable internet access. I mean, I just want more high-quality bilingual polling of states with significant Hispanic/Latino populations."	B	"I know it's hard to quantify, but there are many other factors that are not considered in your ratings that are determinative of quality polling. Happy to discuss offline."	too little	I'm obviously a big fan of online polling.	Not sure		No		No	From my understanding of it there is a lack of randomness and the weighting schemes are skewing the data.	"No, not in my experience."	"Our polling in this year's primary was pretty good. It was a test case for us, adjusting methods after the Massachusetts 2014 primary, where almost all public polling was terrible. And I think we came out pretty well."	Difficult to say -- manmade or natural disasters? 	Not sure		No		All of them.	Hillary Clinton		45	55	Lose the popular vote?		2	98	52	225	"If you have a partisan background, as most pollsters do, do you think that makes you more likely to demonstrate in your work that you are not influenced by your partisan history?"About the same		"No, leave as is."	Less		New Hampshire	"Assuming Pennsylvania, Virginia, Colorado, and the upper Midwest are done deals, New Hampshire gets Clinton past 269 electoral votes."	B	"On the one hand, it's probably fairly objective and informative to the public (although more so for outlets that conduct a large number of public polls in major races, and less so for outlets that do not, and thus provide you with fewer gradable data points). On the other hand, it's also kind of rude, and I'm not sure it makes the connection to the the real lives of the people who make a living in this business and who are well trained and making every possible effort to be accurate. Along those lines, it would be a lot more credible and acceptable if FiveThirtyEight also tried running its own polls so you had a hands-on understanding of the challenges involved. Additionally, and maybe the worst unintended side effect from your perspective, I think it encourages herding. If people want to avoid getting crappy grades from you, the smartest thing they can do is produce results that are in line with the polling average (we NEVER did this at Merriman, BTW). Because we all know that the voting outcomes are likely to regress toward the polling mean, it's just mathematically the most sensible thing to do. And worst-case scenario, you may end up really wrong, but no more wrong than average. So, bottom line, I think the grading system, because it is so influential, potentially encourages poor behavior as much as it calls it out."	too little		Not sure		Not sure	They're likely testing various turnout models and not comfortable until they map against actual voting data.	No	"I think they are using too small a panel and potentially spoiling it by going back over and over (turning these folks into higher-information voters). I think it's an interesting idea as an experiment, but not as a tracking poll like they are using it. Essentially I think they are misusing it."	Not as much scrutiny of their methodology. They are less rigorous and robust.	Oversample and more weighting.	"Obviously the final debate will be big, but will it significantly move the polls (and predictions)? It's unlikely. There are also rumors floating around that more leaks (for both candidates) are coming, which could have an impact."	Not sure	There are not enough states with strong state-level poll data to figure this yet.	No		Another fantastic question. 	Hillary Clinton		20	70	Win by 10 or more points nationally?		7	93	49		Please briefly describe in a few sentences the way in which you determine demographic targets for weighting your surveys.About the same		Not surprised. i don't know the answer to the second question.	Less	"Most reasonable people have learned from their mistakes in 2012 (and 2010 and 2014) about listening to unskewers. If someone is trying to unskew a shit poll, they've just made it a shit poll that is more favorable for their preferred candidate. It's still shit. And most unskewing people right now are frantic Trump partisans who can't acknowledge that their preferred candidate is not actually the preferred candidate of most of America. That Clinton supporters were unskewing polls when the race got close reflects poorly on them as well. There are a lot of people happy to support a walking 4chan commenter as long as they believe he will lower taxes and punish women and minorities, because they view the world as a zero-sum game. If someone else is better off, then I must be worse off. It's like they don't understand how the world works."	Ohio	Pretty unique this year	B		too much		Not sure		Not sure	"Does it do horse-race polls and not release them? Didn't realize that. If they do them, they should release them."	No		"Often the case -- campaigns spend more money, more insight."	"Spend tons of money hugely oversampling members of those groups. Or, find another way to reach them."	"The cake is mostly baked now, but with Trump, who knows."	Not sure		No		Cell-phone-only respondents. I want to be able to prove that they are different people than landline respondents even if all the basic demographics are the same.	Hillary Clinton				Same						What are the biggest lessons you learned from the 2016 election cycle?About the same	"Higher third-party performance leading to potentially wild swings as those third-party candidate voters either show up or don't, plus the insanity of Donald Trump makes the polls much more likely to be off, but in opposite ways. If Trump keeps cratering, insulting everyone who isn't a non-college educated white man and/or a racist, earlier polls will be way off. Also, so many polls are wrong about who is actually on the ballot in states."	"Not surprising, but very interesting. Margin of error (or some new metric) should include some indication of the effect of the weights (i.e., margin of errors of the unweighted bases of the smaller subgroups that are weighted up to the degree that they have an effect on the overall topline should somehow be incorporated). Also, although this is not an margin of error matter, the way each pollster defined their turnout model should be made clear and transparent -- this seems to also be a major factor in that Upshot analysis."	Less		Ohio	Still seems to be a bellwether. 	B-	"They are a useful guide, but their sensitivity to small changes in data undercuts their value."	too much		Yes	Drudge	Not sure	"I guess I don't really care. There are so much data out there at this point, I hardly miss it. My understanding is it has not been released because they could not figure out how to do an accurate likely-voter screen."	Not sure	Not for horse race -- but OK for other reasons that are not being reported. The weighting is way over the top and concern about the Heisenberg principle.	Private polls are more expensive and time-consuming.	"That Democratic polling primary ""bias"" is a result of shit polls that assumed not enough non-whites due to problems reaching non-English speakers or cell phone users. I learned that Michigan continues to be the worst state in the nation (other than Alaska) to poll because no one does a good job there."	The candidates' ground game.	Not sure		No		"In our state we have a difficult time reaching minority voters. I'd like a lot more of them in our samples. I'd take more young voters, too."	Hillary Clinton		10	90	Win by 10 or more points nationally?		3	92	49	227	What weights did you apply?Not sure		"The results did not surprise me. Even with different interpretations by different pollsters, all of the results were within the margin of error."	More		Virginia and Georgia. Texas in the next cycle.	They are up for grabs and Texas will be in another cycle soon.	C	"I love the idea of the ratings, but I think they try to make distinctions that are just too fine. There are good pollsters and there are those who use questionable methods, but beyond that it is difficult to make the fine distinctions that the ratings suggest are possible. I am also concerned that the ratings' measures of accuracy do not take into account margin of error. I've written about some of my concerns in the past, which you can find here: http://www.huffingtonpost.com/guest-pollster/yost_borick_the_silver_standar_b_727850.html"	too much	Just a ton of coverage on horse-race polling... less on everything else.	Yes	"Any poll that has Clinton up double digits in West Virginia (without checking back, I think it's Google Consumer Surveys that leaves the biggest questions along those lines)."	Not sure		Not sure	"I don't know their methodology, but unless they are integrating new panelists in each wave and rotating panelists between waves it seems a risky strategy. A methodology without ""new voters"" creates respondents who are viewing the election as ""panelists"" not as voters and their is no way to correct for the bias that introduces."	"Private polls have more of an agenda, one way or the other."	That pollsters need to let the polls tell the story of the electorate without dictating their expectations and stifling what the poll is supposed to do.	The sweet meteor of death.	Not sure	"I don't know what this question means. Some states will have terrific turnout organizations that defy what one might expect from demographic models. They can defy polls as well. I guess my answer is, it depends."	No		"Infrequent voters, because some of them may turn out this year -- another lesson from the GOP primary."	Hillary Clinton		40	60	Win by 10 or more points nationally?		10	90	49	220	Not sure		"The results were not surprising. I think the clarity of reporting methodological decisions is more important than reporting the margin of error, but the margin of error is still important. Pollsters need to do better at estimating and reporting the margin of error with design effects included."	More	"They've taken it up a notch. Now it's not just skewing, but some on the Trump side are claiming fraud. Sad!"			C	"Past performance is not an indicator of future results. Sure, you know that there are some terrible pollsters, but how do you judge a pollster that is generally very good in one state that branches out to a state that they've never polled before?"	too much	It is being done completely because of cost. Better no poll than a bad poll.	Yes	LA Times/RAND tracker and Rassmussen	Not sure		Not sure		"Yes, because private polling (especially results that don't get presented to the public) is designed to be useful for campaigns, rather than about trying to create a news story. You will ask questions that you never would release to the public in an attempt to understand the race and how everything will go. This year is a presidential year, so it should be basic to poll. If there are differences (which I have noticed), it will be because the public poll you are comparing to is poor, rather than a problem with all public polling."	We actually did a very good job of predicting the Florida primary in a state that has a minority population of over 25 percent. Makes me feel pretty good about polling using online methodology!	The withdrawal of a candidate and/or a candidate and running mate.	Not sure		No		Latino	Hillary Clinton		15	85	Win by 10 or more points nationally?	"Her path to the nomination is easier than Trump's path and recent events have given her a clear advantage. I'm not sure that either event is likely, but I think she is a bit more likely to win by a large margin than she is to lose the popular vote."	10	90			Worse	"I think there is more potential movement in the actual race potentially still to come. Also, wild swings (more than usual) in non-response bias depending on day-to-day candidate behavior."	"They didn't surprise me, because I compare our results to other polls. The wildly different numbers of non-whites, or younger voters, or party ID clearly will lead to different results. Using voting history compared to voter response as to vote likelihood is another issue that can cause problems with newly energized voters. Basically, polling is a magic combination of working with lots of different sources attempting to model something that doesn't exist, and no one can be proven right or wrong in an election until after it actually takes place. Pollsters may have fixed issues from previous years that overcompensate or cause new problems. Margin-of-error reporting is basically a crap-shoot, because the normal calculation is based on a random-digit-dialing sample, which very few pollsters use anymore."	More	The media polls we are seeing are oversampling Democrats by as much a 10 percent based. It is not because they cannot do it right. Most pollsters are trying to save money by not doing the hard work of hand-dialing mobile phones. The polls are inaccurate and that is being proved right on Election Day.			C-	A long conversation.	too much	"There seem to be more online polls in this cycle than in the past. While they are less reliable, they are also less expensive to commission."	Yes	Most of them because polls aren't really about forecasting until very late in the cycle. To use them as forecasting tools too early in the year is wrong.	Not sure		Not sure	"All innovation should be encouraged. Those who suffocate the innovators are not scientists, they are scared children."		"We are still processing the primary results and trying to decide how to adapt, but primary polls are typically more volatile and less accurate than general-election polls."	Too hard to predict.	Not sure		No		"Latinos? It's a group treated as a monolith, but it would help to know how long one's family has lived in the United States for one thing."	Hillary Clinton		15	85	Win by 10 or more points nationally?		5	94	50	230	Worse		Weighting has nothing to do with sampling margin of error. The story displayed a deep ignorance of the role of weighting.	Not Sure				C+	"The ""member of NCPP"" component is dramatically out of date. I sent in a check many months ago and have heard nothing back. Their site hasn't been updated in years. I think I am a member but have no idea. This is the difference between (I would guess) an A- and an A. There are economic consequence for us, since people have started looking at these ratings as a shorthand for quality. Our rating is wrong, and there seems to be nothing I can do about it. I like the idea, but it has to be accurate and real time."	too much	"Online polling is usually panel-based and therefore self-selecting and not random. You may need a 36-year-old white guy, but that white guy on a panel is going to be different from a white guy who isn't on a panel."	Yes	"I see that FiveThirtyEight adds most polls to their model, regardless of methodological rigor and tries to ""adjust"" them. Things like the Ipsos state polls with few interviews -- or other similar ones with either low sample size, poor methodology, etc. -- should not be included in my opinion. It also encourages those pollsters to continue their use of obviously incorrect methodology (see Nate Cohn on LA Times poll for instance)."	Not sure	"It's funny. They said they were not going to do horse-race polls, but I sense they are collecting the data. Maybe they are taking a cycle to figure out likely-voter modeling. But, you know, this year is unlike any other year, so how do you use any previous year to predict what is happening this time?"	Yes			"We did not have a problem with this, and I am not sure why there would be a problem if someone is working with a voter file that has a good predictor of race."		Not sure		No		Non-regular voters and those who don't participate in polls.	Hillary Clinton		40	60	Lose the popular vote?		11	89	49	237	Worse			Not Sure				D	"Too much weight given to methodology and association membership. And too little given to accuracy. Getting them right isn't rewarded they way it ought to be. After all, it's what drives success in the real world of polling. The criteria used for pollster ratings should not be so disconnected from that reality."		"Some in the media are doing a good job of reporting on the polls and providing insights into the election that are valuable. There is never too much of this type of reporting. FiveThirtyEight and the Upshot are examples of this. On the other hand, there is still too much attention paid to polls with suspect methodologies and/or outliers. There is way too much of this reporting."	Yes	Any interactive-voice-response poll.	Not sure		Yes	"I don't think that's the main problem with their poll. Based on Nate Cohn's analysis, I think they're making poor decisions about how to handle outliers and/or individuals with ridiculously large weights."				Not sure	"It really depends on which polls you're including in the model. If you're including crap polls, then it would be the demographics. I'd also assume that the demographics would be closer in Nevada due to missing Hispanic/Latino voters, but the polls in Iowa due to it being a very white state."	No		Uneducated whites	Hillary Clinton		0	90	Win by 10 or more points nationally?		3	92	48	227	Worse	Fewer quality polls. More slap-dash polls.		Not Sure					I have not studied them (sorry).		Depends on the poll.	Yes	"All interactive-voice-response-only polls should not be included; their time has passed. I am not sure what to make of the state-level estimates from Reuters and Google Consumer Surveys. The sample sizes and volatility are eye-catching, and I don't really know what to make of them. But I don't know if I would ""exclude"" them, per se."	Yes	Not sure.	Yes	Approach OK but terribly executed.				Not sure	"You guys at FiveThirtyEight are way to ""into yourselves."" You ought to get out more."	No		White millennials (sub-group size in even the largest samples still too small to have much confidence)	Hillary Clinton		20	80	Win by 10 or more points nationally?	"As the election nears, Clinton should continue to improve among millennials."	4	92	48	227	Worse			Same								Yes	"NBC/WSJ — Of all traditional pollsters, they've seemed to put out the biggest outliers this election cycle. The first was back in February when they had Cruz beating Trump (contradictory to everyone else, and many media organizations grabbed onto this and made it a bigger story than it actually was). This past week, they put out a poll of 447 likely voters that had Trump up by 11. Swings are not that dramatic, especially for two very well-known candidates. To that point -- I would avoid using any poll with a sample size under 1,000 to forecast an election. That sample is too small to conduct accurate analysis, and it does not let you delve into demographics in an insightful way."	Yes	Everyone involved in public polling should. See my response about the grading system for why I think they're not.	Yes	"It's useful to show how events can change the race, but you become very reliant on your sample. I don't think all pollsters should switch to this method, but this has its own pros."				Polls		No			Hillary Clinton		42	51	Win by 10 or more points nationally?		10	90	48	240												Yes	Robo polls. It's just hard for me to take them seriously.	Yes	Fear. Business.	Yes	"Because it can show a difference in how certain respondents feel the need to show that they are proud to vote for their particular candidate. Being able to look at 3,000 or so people who are likely to vote, and then track their changes would be really great. The problem is how they are weighting their results, rather than the method. It's something that would be great, if you have the money to do it."				Polls		Yes	Bilingual interviewing in states where segment exceeds 10-15 percent.		Hillary Clinton		30	70	Win by 10 or more points nationally?		4	91	49	227												Yes	Emerson (no cell phones); LAT/USC (weighting to a proven-to-be unreliable recall question); CVOTER	Yes							Polls	Certain demographic groups may turn out in higher numbers -- certain groups may stay home.	Yes	"It might be useful to reframe basic party-identification question along the lines of ""which party do you usually vote for?"""		Hillary Clinton		0	100	Win by 10 or more points nationally?	I believe Donald Trump can keep talking for four more weeks and say even more racist/misogynistic/horribly offensive things.	5	90	49	230												Yes	Robo polls because they cannot be used to call cell phones.	Yes	They are probably uneasy about how their results compare to other polls. 						Polls		Yes	Marital status		Hillary Clinton		0	51	Win by 10 or more points nationally?		15	85	48	217												Yes	"The online 50-state polls. They're crap. Also, any poll that includes or excludes any candidates that are or are not on the ballot. In North Carolina, Jill Stein isn't on the ballot, so that is (probably) going to help Trump in those polls because they're more likely to vote Hillary. It takes five minutes to find out who's on the ballot in most states, and for people to do polls that don't make any effort to reflect the ballot the voters will see is just malpractice."	Yes	"Because they don't want to be shown to be wrong again with their estimates. If they're releasing results of other questions and questions that rely upon vote, they should release them."						Polls		Yes	"Most phone pollsters cannot go too far into demographics because of small sample sizes, so there is a lot of room for improvement there."		Other (please specify)	Too early to tell	50	50	Lose the popular vote?	Hidden Trump vote	12	85	51	245												Yes	"I would exclude all the wrong ones, of course."								Polls		Yes	Religiosity.																																Polls	"Trump is going to lose some of the typical Republican voters (e.g. college-educated suburban white women), and he'll likely lose the Latino vote by an unprecedented margin. The demographics alone cannot account for the ""uniqueness"" of a candidate who brags about groping women, among other offensive statements."														
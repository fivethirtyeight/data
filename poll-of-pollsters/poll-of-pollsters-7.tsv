"Please enter your information and your polling organization's information. We won't publish your pollster ID, phone number and email address."		"The average presidential poll <a href=""http://fivethirtyeight.com/features/the-state-of-the-polls-2016/"" target=""_blank"">within the final 21 days of the election</a> has been off by 3.6 percentage points since 2000. Do you think that polling error will be better or worse this time?"		"<a href=""http://www.nytimes.com/interactive/2016/09/20/upshot/the-error-the-polling-world-rarely-talks-about.html"" target=""_blank"">The Upshot found</a> that different pollsters can get very different results with same data set. Did the results surprise you? Should pollsters be reporting a bigger margin of error or scrap the way they’re reporting it entirely?"	"How does the amount of <a href=""http://spotlight.ipsos-na.com/index.php/public-affairs/no-you-may-not-unskew-my-polls-a-refresher/"" target=""_blank"">talk of unskewing polls</a> from advocates and the media in 2016 compare to unskewing talk in 2012?"		"If you were given a blank check to poll the presidential race in any state, which state would you poll?"	Why do you say that?	"What grade would you give <a href=""http://projects.fivethirtyeight.com/pollster-ratings/"" target=""_blank"">FiveThirtyEight's pollster ratings</a>?"		Are media organizations commissioning and covering online polls in this race...		Are there any polls you would exclude if you were using polls to forecast the election?		"Should Gallup release <a href=""https://twitter.com/DavidLauter/status/784157638271655937"" target=""_blank"">its horse-race polls</a>? Why do you think it isn’t?"		"Do you think <a href=""http://fivethirtyeight.com/features/election-update-leave-the-la-times-poll-alone/"" target=""_blank"">the USC Dornsife/LA Times poll</a> approach of tracking the same group of respondents over time is a smart one?"		"A <a href=""http://www.nytimes.com/2016/10/06/us/politics/donald-trump-campaign.html"" target=""_blank"">recent New York Times article</a> suggested that private polls show different results than public polls. Is that usually the case? Any reason it would be this year?"	"What lessons have you learned from the primaries? For instance, what can be done to address <a href=""https://twitter.com/NateSilverFiveThirtyEight/status/736217950219309056"" target=""_blank"">the bias in polls in the Democratic primary</a> that depended on how many people in a state are black or Hispanic?"	What are the scheduled events and unscheduled possible events that you think are most likely to move the polls between now and Election Day?	"Do you think that in <a href=""http://fivethirtyeight.com/features/election-update-where-polls-and-demographics-disagree/"" target=""_blank"">the states where polls and demographic-based models diverge</a>, the polls or the demographics will prove to be closer to the result?"		Is there a demographic question you wish were routinely included in all polls that is currently left off?<br /><br /><br />		What is the one group of voters you wish we had more granular polling data about? Why?	Who do you expect will win the 2016 presidential election?		What percentage chance do you give each of these people to win the election?		Is Clinton more likely to...		"According to the national exit polls, what percentage of black voters will vote for"		How many seats do you expect Republicans will hold in the Senate in 2017 -- after the 2016 election? (They currently hold 54.)	How many seats do you expect Republicans will control in the House in 2017 -- after the 2016 election? (They currently hold 247.)	What question or questions would you want us to ask your fellow pollsters in future rounds of this poll?Name	Polling Organization	Response	Please explain your answer:	Open-Ended Response	Response	Please explain your answer:	Open-Ended Response	Open-Ended Response	Response	Why would you give it that grade?	Response	Why do you say that?	Response	"Please explain your answer, and say which polls you would include or exclude:"	Response	"Please explain your answer, and say why you think it isn't releasing them:"	Response	Why? Is it one you have used or will consider using in the future?	Open-Ended Response	Open-Ended Response	Open-Ended Response	Response	Why do you say that?	Response	"If yes, please specify and explain why."	Open-Ended Response	Response	Other (please specify)	Donald Trump	Hillary Clinton	Response	Why?	Donald Trump	Hillary Clinton	Open-Ended Response	Open-Ended Response	Open-Ended ResponseSteve Koczela	MassINC Polling Group	Worse	"With the proliferation of methods, it wouldn't surprise me to see less convergence this year as we approach Election Day than in past cycles."		More	"The use of ""clickers"" by ostensibly responsible adults is a new development this year. Unskewing based on Party ID feels sort of quaint by comparison. "	Georgia				just the right amount	"I assume you mean polls and not ""clickers""? By the way, PINOs (polls in name only) is another nomination for a name."			Yes	"I would suggest to be treated as experts in horse-race polling, conducting public horse-race polling should be a necessity."	Yes	"Panel polls are fine. The LA Times poll is consistent in terms of its relationship to averages, which suggests stability in what they are measuring, even if it turns out to be wide of the target. I would take that over a poll that careens all over the place from week to week."	"With more registration-list based sampling polls in public now, I think there is some convergence between the two worlds. Campaign polls are used for more and different things, but compare a voter-file public poll to a voter-file campaign poll, and there is a lot of methodological overlap. Having done both, I think the wizardry of campaign polling is sometimes exaggerated for dramatic effect."		No idea. I have an emergency popcorn reserve for just such an eventuality.	Polls		Yes	Religion and church attendance. Every demographic question takes up space for a substance question. But more analysis of the reaction of various religious groups to the current election cycle would be useful.	Not sure. 											"What is the social value of horse-race polling? Overall, does it contribute to our political process or detract from it?"Doug Kaplan	Gravis Marketing	Better			Less				A		too much		No		No	They shouldn't if they don't think it's good for their business.	Yes	" We think it's interesting -- something that we are studying especially on the state level. I question why they only have 3,000 instead of a higher amount."		Something we are focusing on building bigger online panels.	The debates.					18-24											Evans Witt	Princeton Survey Research Associates International				Less		Arizona	Interesting state with an increasing Hispanic population. It needs more live-interviewer polls.					No	"A properly constructed model can take advantage of all available data, even if some of it is flawed. This is not to say that some polls might be weighted down to a tiny, tiny number."	Not sure	It is their money. Those are their polls. Gallup has explained their position.	Not sure	Panel surveys can show individual-level change. And that can be very interesting. They are much less robust in showing overall changes in attitudes.	"It is always the case. This year may be crazy, but not on that dimension."	Primary polls are inherently quite difficult. There is a lot more that needs to be studied to understand the lessons of the 2016 primaries.	"Oh, a debate, perhaps. "			Yes	Marital status. Often a very strong predictive trait.												Bernie Porn	EPIC-MRA	About the same	"There have been so many unusual and unexpected things happening in this election, it will likely be more difficult to predict polling accuracy in this election than in past elections, which means things will probably be about the same."		Less	"There seemed to be more comments in 2012 than in 2016. In 2016, there are more comments from Trump supporters claiming that crowd size is a better reflection of support than polls, which is a much more extreme position than talk about unskewing polls."											No	"If the voters selected are off, as they appear to be, they are stuck with that bias for all their polls. "			"The third debate, and any new revelations about Trump or Clinton, which are unknown."	Polls	Demographic models may be less reliable this year because of the high unfavorable ratings of both candidates.														Bradley Honan	KRC Research			No -- they should release the weights they use and what the demographic makeup of the survey is -- something that can have a profound impact on the final data.																																	Nick Gourevitch	Global Strategy Group	About the same	"I think there is more uncertainty around how the polls will translate to the overall outcome this year as there are a number of aspects of this election that are different than the last couple of elections. Some of these factors include the lower popularity of the candidates and 3rd party candidates polling at a significant number -- both of which may cause potentially unusual turnout dynamics. But I don't think that necessarily translates to an average outcome that is all that different from the polls relative to prior elections. In other words, I think it's just as likely to see the polls hit it dead-on as see a big miss."	"That did not surprise me at all. In an era of low response rates, every pollster must make their own set of assumptions about their demographic model and who is going to turn out to vote. The idea from the old days of just letting it ""fall out"" by doing a random-digit-dialing poll is just not possible anymore. In other words, even those pollsters who use random digit dialing are making a decision to do so and making assumptions about how their random data projects into a likely electorate. So with all these different techniques, you would expect different results from the same data set. In terms of reporting margin of error... I'm not sure I see a huge problem with the way it is being done now, which at least is a standard based on sample size. If we introduce other criteria it will probably lead to different interpretations and inconsistency and the metric will become meaningless. But it's probably worthwhile for pollsters to report more about the processes they use to create their demographic and turnout models."	More	"There was a ton of unskewing going on in 2012, so I hesitate to say that there is more this year. But I will just because of the absurdity of the unskewing going on by the Trump side -- referencing fake website polls as real data, talking about crowd size and yard signs as real metrics, talking about hidden voters without a shred of evidence, etc. What they are pushing is just so far removed from reality relative to any polling discussion that was going on in 2012. The unskewing of 2012 was mostly about party-identification differences of a few points -- and that discussion seems quaint in comparison to today (like most things about 2012 vs. 2016). "	Alaska	Seems like some fun stuff going on up there but a really hard state to poll so you'd need that blank check.	C-	"I have three main concerns about the FiveThirtyEight pollster ratings: First, as a private campaign pollster, it's hard to accept a rating that is based on less than than 1 percent of the polls we have conducted over the time period in which FiveThirtyEight has collected the polls upon which they base their ratings. There is nothing for us to do about that, of course, because we are not able to release most of our polls that are done privately for clients. But we generally have no control over what is released and our rating is dependent on polls that are released -- which in turn are the polls that are most likely to be ""good polls"" for our clients. We know our record based on our private polls and the FiveThirtyEight score just doesn't reflect that. I understand why FiveThirtyEight does what it does -- it needs to help the public interpret the polls that are in the public domain. But it's just not an accurate reflection of our work. Second, that the ratings treat all elections equally and judges accuracy in the same way under all circumstances. Based on experience, polling accuracy is highly dependent on the type of election and the candidates. For example, a House race poll conducted three weeks out showing a well-known incumbent up 10 points against an unknown challenger is likely to tighten. A presidential campaign poll showing two well-known candidates, with one up 10 over the other is much less likely to tighten. But accuracy is judged the same way in all cases. This is just particularly problematic in House races and other lower-information polling. Finally, I don't love that FiveThirtyEight makes no effort to evaluate the accuracy of polling done more than three weeks out of Election Day. That is a much harder exercise but basically any pollster can do whatever they want as long as it's more than three weeks out and not be judged on it. It creates a low incentive to care about accuracy or methodological strictness until the end. This is a harder problem to solve, but worth trying."					Yes	They are one of the giants in the field and they should release the data instead of just giving up. Predicting elections is a problem that all pollsters are trying to solve and the more data the better. Opting out removes a valuable resource from the system.			"I think private polls are generally more stable (and less volatile) than public polls as private pollsters use voter-file metrics and proprietary predictive models for sampling and weighting that is not necessarily available to public pollsters (although some are starting to use it). Generally speaking, public polls seem to take the ""highs"" higher and the ""lows"" lower than private polls -- responding with bigger swings to campaign events."					Yes	"Don't have a single one. Ideology is not ALWAYS asked and it's always a crucial one to me to help segment voters within parties (i.e. liberal Democrats vs. non-liberal, very conservative Republicans vs. non-very). Beyond that it's often state- or region-dependent."												Jay H. Leve	SurveyUSA																																				Kyle Dropp	Morning Consult			The results did not surprise me. It is further proof that transparency from pollsters is extremely important. There is not enough of that right now in the industry.							too little	"Everyone should be experimenting with multiple methodologies and modes. Frankly, there is too much coverage of polls with small sample sizes and outdated methodologies. We should be pushing the survey-research field forward and that cannot happen if we are not looking to new methodologies and ideas."					Yes	"The approach is very interesting, and I think it is good for our industry to be trying new methodologies such as panel surveys. No one is perfect right now. The biggest challenge with this method in particular is getting a good sample from the outset and using the right variables to calculate survey weights."		We need to focus on larger sample sizes and methodologies that allow you to reach these demographics. Traditional phone polls are limited in this.	"If we learned anything from this election, it is very hard to change public opinion about Donald Trump or Hillary Clinton. They are widely known and most voters already have a set opinion of them. Any changes in their support, due to major events, have been small and dissipated quickly."					"Younger Hispanics. Nobody has good data on this right now, and that demographic will only become more prevalent."											Andrew Smith	University of New Hampshire	About the same		"No. The differences were due to weighting, which has nothing to do with margin of sampling error. There are many other sources of error in surveys, but unfortunately, most are extremely difficult or impossible to quantify."	Same	People want to spin unfavorable results.	New Hampshire	I know and understand the state.	B	Not enough emphasis paid to the methodologies that polls use.	too much	They have no sampling theory to justify their use of convenience samples. They are just cheaper than other polls.	Yes	Any poll that does not start with a random sample. Any poll that does not include cell calls. Any poll that has a field period of less than four days.	Yes	Don't know their reasons for not releasing.	No	Too much panel conditioning and panel attrition.	"Yes. Private polls, typically conducted by campaigns, typically rely on different sampling frames (voter lists rather than random-digit-dialing) and often model their polls to fit their expectations of what the electorate will look like."	"Understand that polling in primaries is a perilous act, especially in early primaries. Typically, voters decide who to support very late and they have few strong attachments to candidates, certainly as compared to general-election polls."	"Debate, more Wikileaks dumps, terrorist events"	Polls	Shouldn't assume what the electorate will look like.	Yes	How often you attend religious services. This is the second biggest predictor in elections after party identification.	No	Hillary Clinton		35	65	Same		5	95	50	222	Barbara Carvalho	Marist College	About the same		"No. There is no standard method for identifying likely voters. Many methods are, in fact, proprietary. Margin of error is statistical error."	Less	There seems to be a better understanding now about how polls are conducted and the differences between measures of party registration and party identification.	New Hampshire	It's a swing state with a competitive Senate race that provides insight into the divide in the Republican Party between pro- and anti-Trump supporters.	A	Seriously evaluates the methodology and transparency of the polling organizations.	too much	"Although there are places that consumers of polls can go to get an informed look at the polls, there are still too many questionable polling methods that are used and reported."	Yes	"Polls should provide a narrative along the way, not just forecast. Those that bounce erratically around suggest methodological concerns. Polls to ignore are interactive-voice-response polls, live-interviewer polls without cell phones, online polls from convenience samples, and the USC panel poll."	Yes	If they are going to release part of the poll (as in the information used to ID undecided voters) they should release the horse-race and other information about the poll in accordance with transparency.	No	There is a good deal of research regarding panel effects and the impact that has on results. No.	Private polls and public polls have different approaches. Private polls try to model the electorate they think will turn out; public polls generally identify who is likely to participate. Sometimes there is compatibility and sometimes not.	We didn't have that problem.	"The early vote, a health issue on the Clinton side, more videos on the Trump side."	Polls	Demographics provide a foundation of what has transpired in the past but polls provide real-time changes. We've seen changes this election cycle in how demographic groups are aligned.	No		"Asian Americans: They are a growing segment of the electorate, thought to be Republican, but may be shifting."	Hillary Clinton		20	80	Win by 10 or more points nationally?	She is stronger in larger populated states so not likely to lose the popular vote.	6	92	49	238	Chris Borick	Muhlenberg College	About the same	I think there are some countervailing forces at play that will likely produce similar accuracy to past presidential election cycles. On one hand the sheer number of polls and thus the number of individuals polled will be higher than ever and thus on the whole produce some enhanced accuracy effects. However some very marginal poll methodologies within the aggregates may act as a negative force in terms of accuracy and thereby detract from the gains produced from the larger sample size within the aggregation of polls.	"This did not surprise me in the least. Unlike when pollsters weight to fairly known population parameters in general population surveys, weighting to likely voter parameters includes much more discretion on the part of the pollsters. Thus when good pollsters were given the same raw data they may make some significantly varied choices on weighting. While adjusting margin of error for non-sampling error can help produce a more realistic margin of error, I still think that the margin-of-error measures are probably not what they purport to be. I also remain puzzled how non-probability surveys calculate margin of error and why such accuracy claims are even published by reputable sources."	Less	"I think the craziness of the ""unskew"" efforts of 2012 have helped hold down a repeat of that scene from 4 years ago. It has morphed a bit more into the ""hidden Trump voter"" critique but I don't see the same broad efforts that were in place in 2012."	Pennsylvania	My answer is of course as biased as they come because I do poll Pennsylvania and would certainly love unlimited resources to enhance those efforts. It's a great state to poll with its really varied electorate and I would love to be able to have much larger samples to look at sub-groups.	A-	On the whole I think it's a pretty solid measure. I think there are some aspects of the measure that can be debated but on the whole the scores for pollsters seem to capture accuracy pretty well.	just the right amount	I think online polls have great potential and just like phone polls can vary greatly in terms of the strength of the specific methods they use. Let's see how they perform this cycle.	Yes	I certainly have some major concerns about telephone polls that don't include cell phones. The weights that these polls must use for undersampled demographics (e.g. young voters) must be off the charts and therefore really scare me. Thus I do discount these type of polls in any forecast.	No	It's Gallup's choice. I think the issues they had in recent cycles have produced some internal concern about their models and thus they simply may not have the confidence to release these results. If the Gallup team draws this conclusion it's their right to withhold their findings.	Not sure	I think there are some really interesting aspects of their methodology but anchoring the results so strongly to 2012 does raise some major questions.	I think this is fairly common and I'm not sure if there is anything different at play this cycle.	I think primaries are much more difficult to poll than general elections with turnout much more volatile. Certainly some of the accuracy concerns related to racial and ethnic characteristics should be examined moving forward with adjustments made.	"With some increased volatility in polls this year compared to 2012 it appears that events may've more potential to meaningfully change the race. I certainly expect the recent release of the Trump comments on women to move the numbers. A terrorist attack could also move the polls as I believe the attacks in New York and New Jersey did marginally last month. As for scheduled events, the debates seem like the best bet for some poll movement in the last month."	Same		Yes	There are a bunch I wish I had room for. In election polls we haven't really done much with sexual-orientation measures and I would love to be able to include questions on this factor in election polls. 	This is a tough one. I would love bigger sample sizes for so many sub-groups. If forced to choose one it would probably be race. In Pennsylvania given our sample sizes and fairly small non-white population we just can't get very granular with racial demographics such as African-Americans and Hispanics. It certainly would be great to have larger samples from these communities.	Hillary Clinton		30	70	Win by 10 or more points nationally?	"While both are unlikely, it's harder to win a blowout in a presidential election given the deep partisan division in the U.S."	12	86	50	235	Christopher Budzisz	Loras College	Worse	"If Trump continues to struggle and scandals mount, we may see more people shying away from publicly stating that they are supporting him (something like a social desirability bias), although they may in the end still vote for him. I also wonder if perhaps we will see a larger-than-normal spike in the number of respondents who refuse to answer the ballot questions the closer we get to Election Day."	"No, the results were not surprising. I do think that the experiment deserves a lot of credit in helping to educate the public regarding polling practices. Consistent transparency in the exact parameters of weighting would be a good universal practice. As the polling industry moves past this election, I do think the focus on margin of error will be diminished, but not simply for the reason that different pollsters can render different results with the same data. Non-probability sampling, and concerns over things like non-response, will likely drive things away from a simplistic conversation of margin of error."	Not Sure		North Carolina	"The state's diverse, and diversifying, electorate (in all senses of that word), coupled with the gubernatorial and Senate races on the ballot, as well as the state's historical voting patterns, provide fertile ground for comparisons among voters and groups. In addition, the state provides, via the Senate and gubernatorial race, a test of presidential-candidate impact down-ballot. Three birds with one stone!"	A-		just the right amount		Yes	"As Nate Cohn has pointed out, the USC/LA Times poll has proven problematic this cycle due to a confluence of methodological decisions and some ""bad luck"" regarding who was in their panel."			Not sure	"I don't know if I would say it is smart or not, but it is gutsy as it relies so much on the composition of the panel -- a group it cannot simply replace under its methodology. And, as we have seen, its weighting can get pretty extreme."	I believe that such differences between public and private are not atypical.		"In terms of unscheduled events, if more accusers against Donald Trump come forward, especially if there are recordings or other evidence, that could drive Trump down further. The final presidential debate could also have an impact. Unless the Wikileaks releases regarding Clinton get more serious, I don't see much changing electorally from these events."	Not sure		No		"In the context of this presidential election and trends in religious practice, I think a more granular look at the burgeoning population of Hispanic Evangelicals would be pretty fascinating."	Hillary Clinton		10	90	Win by 10 or more points nationally?		5	95	49	232	Spencer Kimball	Emerson College	Worse	It appears this year's electorate is more volatile than we have seen in the past. The primaries showed big shifts from polling data like we saw in Iowa and New Hampshire for the Republicans and Michigan and Wisconsin for the Democrats.	"No, this was not surprising that the numbers varied 4-5 points between pollsters because of the discretion used by pollsters in determining what weights and parameters they use."	Not Sure	Party affiliation is one of the best indicators of voting intention regarding political choice and should be taken into account when weighting the results.	Ohio	"As goes Ohio, so goes the nation. This is a must-win for Trump and without it the race is essentially over."	B-	Too much emphasis on mode and methodology and not enough emphasis on the actual accuracy of pollsters.	too much		Yes	Online polls	No		No	This form of a panel study has flaws that could include a bias sample and all data from it could be skewed.	We trust the private pollsters as much as we trust the public pollsters as both aim for accuracy at the end of the day.	Registration dates and voting registration patterns within states to see the excitement of different voting blocs.	"Debates including Oct. 19, healthcare premium increases in early November, a candidate dropping off the race."	Polls				First-generation Americans	Hillary Clinton				Win by 10 or more points nationally?	At this time Clinton has the momentum and as voters leave Johnson and Stein her numbers should increase.	10	90	50	220	Anna Greenberg	Greenberg Quinlan Rosner			"I don't think the issue is the overall margin of error; the issue is being clear on your choice of sampling frame (i.e., how you define a likely voter) and demographic representation within the sample. And also to remember that unrepresentative data are unrepresentative even if you weight them. So if you show millennial data without cell interviews, they are unrepresentative even if you weight the data."			Georgia	Races have seemed closer here in recent years early in the cycle and then reverted to partisanship. I would like to know if Georgia is the next North Carolina.	B	It is very hard to give pollsters in the private sector ratings because we don't release most of our polls publicly. So I tend to only pay attention to ratings for polling firms that release most of their data publicly like media polls.	too much	Most online polls are not representative random samples; more importantly they grossly underrepresent minority and younger voters.							"I believe this claim is true. Private campaign polls are much more likely to use voter file and live calling including cell-phone interviews. We tend to understand turnout patterns, including geographic and demographic differences in turnout, than public polls. We also know more about the kind of campaign contact voters are receiving and what sort of field effort is being made."	"Bias is a result of poor sampling procedures and not understanding historical turnout patterns. If you know how to screen for a likely voter and know what proportion of the sample should be comprised of minority voters, you are less likely to have bias. This is standard operating procedure. Many primary polls just talked to registered Democrats rather than likely Democratic primary voters so it is not surprising that so many were ""wrong."" That said, Democratic turnout was lower in the primaries compared to 2008 so accurate polling in the primary contests would have required being able to accurate predict turnout, which is not easy."	"The final debate could be the final nail in the coffin for Team Trump. At this point, it's all about GOP turnout. In other words, if the meltdown continues and reduces GOP turnout, it could have a huge down-ballot effect?"	Not sure	"I think you need to take into account both; you cannot understand millennials in Iowa and Nevada without the polling data since so many are supporting Johnson/Stein. On the other hand, adjusting by historical performance helps moderate the impact of outliers, etc."			"I feel like we have a ton of data on different groups of voters. I worry more than we don't have quality or accurate data about those groups, particularity hard-to-reach populations."	Hillary Clinton		43	52	Win by 10 or more points nationally?		2	98	50	227	Mark DiCamillo	Field Poll	About the same		"Margin of error is not understood to mean sampling error by most in the public. Also, given the declining response rates of polls, it has declining relevance. It should probably be scrapped."			No opinion	"Since I only poll in one state, I would have less confidence about the measures I got in others."	B	"Unfortunately, attempting to affix a single forecast number that (appears to) convey some sort of probabilistic certainty to the outcome of the election in my opinion can't be done. However, I must admit that like many others I follow your estimates and give greater value to yours than others."	just the right amount	Online polls should now be reported alongside traditional telephone polls. 	Yes	 Interactive-voice-response polls that don't adequately represent cell phones.	No	"They made an editorial decision against doing so, and as long as that decision is not selectively enforced, it should be left to them."	No	Their poll has little equivalency to other credible public polls and yet has been reported by many as if it were. This poll has been more of a distraction than a help in understanding the dynamics of this year's election.	Private polls tend to pick up a new breaking trend or new development quicker than public polls.	"In heavily Hispanic states, polls need to conduct a larger proportion of their interviews in Spanish, a segment that in this election cycle was more strongly supporting Clinton."	The answers pollsters give to this question have no greater value than any other political observers so why ask this of us.					Asian-American voters. They are a polyglot and are rarely represented well in polls.	Hillary Clinton				Win by 10 or more points nationally?	She has greater upside advantages now than downside.	20	80	Fewer than 50	Fewer than 247 but retaining the majority.	Daniel Gotoff	Lake Research Partners	Worse	The unwillingness of some to vote for Hillary may be understated.		Less				A-	Sometimes ratings seemed to be based on small numbers of (public) surveys conducted.	just the right amount				Yes					"Set appropriate quotas, work to get interviews done among undersampled populations."	"Last debate, obviously. Maybe 9/11 families' lawsuit against Saudi Arabia. Additional leaks/Wikileaks."					Millenials (by race/ethnicity and by gender)	Hillary Clinton		38	62	Win by 10 or more points nationally?		5	95	50		Frank Orlando	Saint Leo University	About the same	"One would like to think that it would be better, but I think it's likely to be about the same. First, although there are more polls out there today than in 2000, the quality of the polls varies widely. I think an underrated aspect of this is that there's a possibility that pollsters that aren't in the field until the very last day will miss a key event that could alter the final numbers. There's clearly a volatility in 2016 that didn't exist in most of the last few cycles which might make it difficult to figure who is going to turn out and for whom."	"Pollsters should definitely be more open about how they derive their data and about error, but most voters and members of the media are only going to focus on the top-line numbers anyway."	Less	"It seems like less, but I still get messages from campaigns asking me why our polls are favoring one party or the other. I can't compare it to 2012, because we're a newer outfit."	Florida	"It's the state we know, and it is the state that we're most interested in. Despite the fact that it's probably not the tipping-point state this time, it is still fascinating!"							Not sure	It's not up to me to tell Gallup what to do with the data they collect. They must think they have more to lose than to gain by releasing horse-race. They're already at the top of the game; their reputation can only diminish if they miss.					"Uhh ... I'm just spitballing here, but probably more Trump bombshells ..."	Polls	"The polling, especially in this election. Demographic models are based on traditional voting patterns. This election may be altering how certain demographic groups act, and so it will take a while for the demographic models to catch up."				Hillary Clinton		5	95	Win by 10 or more points nationally?	The current collapse of the Republican Party seems like a good place to start ...	4	93	50	225	Gabriel Joseph	ccAdvertising	Worse	Pollsters are having a difficult time getting their samples correct. Things change quickly. Just look at what happened in Colombia last week. Polls were off by 15 percent.	"Yes. Their margin of errors should be 10 percent. Look at the past elections from 2014 USA to Israel, Britain, Brexit, and Colombia. Also the primary polls were terrible."			Ohio	It is the most reflective of America. 	C+	All of the reasons given above.	too much	"It is less expensive, has a faster return, and there is no accountability. The polls they run are proving inaccurate as well. Online polls are too selective and have the same respondents over and over. "	No	"The inaccurate polls help shape the election. It is very easy to ""fertilize the polling"" arena based on what pollsters are doing today and when they refuse to change. Shaping poll results has become a profitable business. You want your opponent to think one thing when the opposite is actually what is taking place. The Cantor-Brat race in 2014 is a great example. Also the polls in the 2014 races, Israel, Britain, and Colombia are examples of how you can use technology to keep your opponents and other pollsters off base so that what your clients want to happen actually does. Inaccurate polls result in millions of dollars being spent in the wrong place at the wrong time."	No	Ditto! Their polls are some of the easiest to influence. 	Not sure		"I believe this is ""strategist spin."" Any pollster marketing their services wants their polls to be known and known to be right. I call BS on this theory. The only reason to keep private polls private is because pollsters do not want the public and their clients to know how bad their product and their processes are. If it became known that polls can be manipulated by outside forces when wanted, it would cause changes in the industry that the current market leaders could not tolerate."		 Wall Street events and continued terrorist attacks will influence the elections. WikiLeaks disclosures. A candidate wins an election when the opponent reacts to what they do.	Not sure		No			Donald Trump		70	30	Lose the popular vote?	"Lose by 10. She already has. The enthusiasm factor. They are ""begging"" their supporters to turn out, not asking."	27	83	55	245	Matthew Towery	Opinion Savvy	About the same		"It wasn't at all surprising. We all have different turnout models, so inevitably we will have very different final results. Weighting benchmarks matter tremendously. That said, margin of error is a useless metric that should be scrapped, or otherwise ignored by the reporting media."	Not Sure	"I'm not sure about unskewing, but there has been much talk of ""uncucking."" Can a poll be both unskewed and uncucked? Does one precede the other? Maybe this is a question for Breitbart..."	Florida	"I already poll Florida regularly, and that's partially because I know the state well (proximity, etc.). That aside, Florida is a bizarre, demographically complex place. North Florida is essentially South Georgia, with a few caveats. Central Florida/I-4 is much like the rest of the South -- or perhaps the Midwest -- but with some Northern transplants and a significant Latino population. South Florida is extremely diverse and cosmopolitan, while the Panhandle is affectionately known as the ""Redneck Riviera."" Add to this the importance of Florida in the presidential race, and it's hard to imagine a more attractive state for genuinely interesting polls. "	D	"I'm assigning the pollster ratings a D grade because FiveThirtyEight and its model have abandoned empiricism. I say this for two reasons, the first applying to my organization exclusively. On multiple occasions, I have contacted FiveThirtyEight to explain that we are not affiliated with another organization to which our name, and subsequently our assigned letter grade are attached in the pollster rankings. While we completed work for this organization two years ago, this organization in no way reflects our own methodology, partisanship, etc. Not only is it unfair for our own letter grade to be dependent upon an organization that conducted the bulk of its polling while I was still in high school, but it contradicts the empirical nature of the model itself. Our accuracy, house effect, and other metrics will inevitably vary from that of an unaffiliated organization, and the erroneous assignment of such data will affect the accuracy of FiveThirtyEight's statewide polling models (which assigns weights dependent upon pollster rankings). The second reason carries a similar line of logic: The model assigns a blanket penalty for any pollster that does not use the ""gold standard"" method of live callers. Case-in-point: SurveyMonkey has a C- according to the current rankings. Need I say more? Not only has FiveThirtyEight partnered with SurveyMonkey to conduct research in the past, but SurveyMonkey has had a fantastically accurate year, given their primary results. If empirical accuracy was truly important to FiveThirtyEight, the ranking model must be updated to accommodate methods other than live-caller. Contrary to the current model, internet and mixed-mode polls can be -- and have largely been -- both methodologically sound and accurate of final election results. Please update the model, and for my sake, please at least update our ranking to reflect our actual work."	just the right amount		Yes	"The USC/LA Times poll probably shouldn't be considered a poll, per se. It's a tracking panel, which is useful for some purposes, but requires interpretation."			No	"It's a static tracking panel, which shouldn't really be understood in the same terms as other polls. As mentioned, it's useful, but readers-at-large need more context to understand its results."	"That's sometimes the case, and there are plenty of reasons as to why. I don't think that this year is special in terms of public vs. private, but we also haven't heard much regarding private polls (horse-race-wise, at least)."	"Before you go into a state, learn its demographics inside and out. That's the easy part; the hard part is figuring out how to reach all of those demographics. Sometimes you need to think outside of the [phone] box to provide a voice for those who will otherwise be unheard."				No			Hillary Clinton		10	90	Win by 10 or more points nationally?	"As it stands now, both are very unlikely. But given the recent news events and trajectory of the race, it's looking more and more likely that a blowout is possible."	8	92			Geoff Garin	Hart Research Associates	About the same		I would have been more surprised if everyone came up with the same result. The most difficult part of election polling isn't reaching cell phones or compliance rates -- it is accurately representing the composition of the electorate. There is not a perfect science to knowing the interaction between vote history and a voter's motivation (or lack thereof) around a specific election.	More	"I don't know if it's more, but it certainly is louder because of social media. And there is a much greater (and unreasoned) sense of deep conspiracy around this among fanatics."					too much		Not sure	"I generally accept the idea that the more you include the better, unless there is some reason to believe that a particular pollster puts his/her thumb on the scale."			No	"Re-interviewing respondents produces valuable insights, but making people part of a panel like this changes the way they experience the election relative to other voters. The panel for this should be much, much larger, to reduce the number of times any one respondent answers."	"The private polls I know about generally are done with more rigor. There is very little private polling on the national trial heat -- they are mostly state-based. And too many of the state-based public polls are quick and dirty. But in states where there are a lot of public polls, the averages of them come closer to what the private polls are showing."							Voters under age 30 by race and gender; Hispanics by language preference and number of generations in U.S.											Ann Selzer	Selzer & Company			"No surprise. There are lots of ways of making assumptions about some future event. Not every crystal ball shows the same picture. I did not think the difference between pollsters was due to error. So, no need to scrap what it is the margin of error measures. It's just clear pollsters are not replicating each others' work."	Less	"I might not be seeing all the ""unskewing"" talk that is out there."	Florida	It's a complicated state that matters a lot!	A	"You do your homework. People sometimes think I handed you my track record, but I didn't even know what you were up to. Transparency is great, so it's easy to understand things. Well, the one thing I don't necessarily agree with is ""house effect."" It assumes that the average is ""truth,"" so veering one way or the other is the product of some element of my method. But, then, maybe I just don't understand it as well as I should."	just the right amount	It's all still experimental. So we'll see how things shake out after the election.					Not sure	We'll see.	"Private polls have a different goal -- move the electorate. So, hard to say what assumptions they make. Your own experiment showed that pollsters differ, so I would expect some private to differ from some public."		"Virtually every day, something happens that occurs to me could change everything. I expect many more of these events between now and Election Day."			Yes	"Fantastic question. I'll be client-driven in my answer and say ""amount invested in stock market."""												Benjamin Margolis	Hickman Analytics																				"Donald Trump spontaneously combusting on live TV. I assume you wrote this before the Trump tape came out, but that is exactly what I was waiting for, actual evidence that cannot be denied that Trump is human scum who doesn't respect anything other than his own power. I'd assume a debate could change things if Hillary passed out on stage, or Trump actually punched a baby. I'm also pretty sure that if Trump did shoot someone on 5th Avenue now, Paul Ryan would condemn him, but still vote for him. Most other people would not vote for him, unless they're neo-Nazis or don't mind neo-Nazis if they're for eliminating the estate tax."																Krista Jenkins	Fairleigh Dickinson University (PublicMind)	Not sure	"I lean toward ""worse"" given the perfect storm of methodological challenges and this highly unpredictable contest. But then again, with the Trump meltdown, this could end up being an easier election to call with good precision."	"No because it depends on the respondent base used, weighting, etc."			Ohio	"As Ohio goes, so goes the nation..."	A		too much	There is far more to an election than the horse race.	Yes	Online non-probability polls						A continuing commitment to improving our methodology.																	Seth Rosenthal	formerly of Merriman River Group																																				Adam Geller	"National Research, Inc. "																																				Patrick Murray	Monmouth University																																				Berwood Yost	Franklin & Marshall College	About the same			Less	"I've heard much less talk about ""unskewing"" so far this cycle, but there is still time. I think I've heard more talk this cycle of a ""hidden"" vote for the Republican candidate than I've heard about ""unskewing."" Then again, perhaps I look past the ""unskewing"" talk since it was completely debunked in 2012. "																															John Della Volpe	SocialSphere/Harvard Institute of Politics			"Not surprised; I'm not confident that anyone can know / does know turnout rates for emerging groups like millennials, Latinos, etc."																																	Brock McCleary	Harper Polling						Pennsylvania	"The Philadelphia suburbs are motivated to defeat Trump. Working-class Democrats have flocked to him from all corners of the state. While Pittsburgh hangs in the balance, and with it control of the Senate. The demographics and drama are equally compelling."																													Robert M. Domine	Critical Insights	Worse	General unpredictable nature of this campaign. Who knows what the next episode of this drama will be and how the electorate will respond?	This is not surprising. The art and science of polling -- or of all survey research for that matter -- will always hinge on the competence and creativity of the researcher.	Same	The talk of unskewing the polls lies at the very edge of what most commentators and pundits are qualified to discuss... and the vast majority of the electorate is not interested in this nuance of balancing sample to population.	Ohio	"I'm a Michigan Wolverine... and we're always interested in what the folks in Ohio are thinking. Oh yes, and it's an important battleground state!"	A	"I recall a finance professor demonstrating (with our class) that a group of relatively well-informed people could always out-perform a single ""expert."" This is essentially what you are doing... with survey research."	too much	"The problem is that an ""online (political) poll"" is typically the worst form of online ""survey research,"" in which respondents opt in. Many of us make our livelihoods from conducting online research with balanced samples -- NOT opt-in. So, in political polling ""online"" has gotten a bad rap from its frequent association with ""opt-in"" deployment, not because it is fundamentally flawed as a data-collection mode. Again, this is a nuance that most pundits, most average citizens, and even a few pollsters fail to acknowledge."					Not sure	"Certainly longitudinal studies can be very revealing. And some of those studies that have tracked families for decades provide rich pictures of social evolution. But is this particularly useful for political polling -- that is, getting the right answer in real time? I'm not sure."			"I think it is entirely possible that we are all part of a scripted election event, in which each week promises to bring a new and exciting twist to a drama-hungry electorate. If this is the case, good luck trying to predict a November outcome based on the public response to this week's ""episode."""																Julia Clark	Ipsos	About the same	"This average narrows as Election Day nears (i.e. it gets more accurate), so it seems a function of proximity to Election Day. No reason it would change notably this year. The larger-than-normal block of undecided or third-party voters adds a little extra dose of potential volatility before Election Day."	"Of course not; this makes perfect sense. Every pollster treats weights, likely voter model decisions, and a host of other balancing factors differently. It would be shocking if the results were the same! This is not relevant to margin of error; the error calculations are associated with the above methodological decisions each pollster is making and so should be reported. Good opinion research should include a discussion of total survey error and reporting that figure as well as the more traditional margin of error."	More	"Please see my piece on this: ""No, You May Not Unskew My Polls: A Refresher"" http://spotlight.ipsos-na.com/index.php/public-affairs/no-you-may-not-unskew-my-polls-a-refresher/ "	Ohio	Ohio is very close and the linchpin in Trump’s path to 270.	B+	We like it because we're rated well :) Hopefully that doesn't change! One thing I like is that the ranking values important criteria like transparency as well as accuracy -- and not just a single final horse-race call.	just the right amount	"The gap in coverage between phone and online seems to have been reduced notably. However we would like to see clearer lines drawn between online polls like Reuters/Ipsos that are conducted scientifically, and the opt-in media polls that Trump’s taken to highlighting."	Not sure	"Generally, no. More data is better and the sheer volume of polls helps to dampen oddities. Possibly I'd consider excluding polls funded by parties or PACs or the like (i.e. with a clear agenda). But not otherwise. "	No	"It is perfectly entitled not to; Gallup isn't beholden to anyone to release data. Plus, it is a commercial enterprise for whom an incorrect election call can have a real business impact. And, horse-race polling is expensive and time-consuming. It isn't like the results of the horse-race polling lives magically inside Gallup and just isn't being published... this kind of polling isn't just a matter of asking the right question and then choosing whether or not to publish it. You need to ensure it runs on a survey vehicle designed to measure the target population appropriately, work continually with your likely-voter model, and assess your sample constantly; they've chosen not to invest the considerable time and energy (i.e. labor by paid staff at a commercial enterprise!) required to work daily on horse-race polls. That is entirely their decision and presumably they've determined it is the right one for their business."	Not sure	It is interesting they're doing it. We're not considering it but don't fundamentally have a problem with the approach. However the Nate Cohn piece and AAPORnet discussion yesterday and today highlight some of the potential pitfalls of this approach and the extreme weights that can result (and problems those can cause).	"No idea. We don't see private polls, except after the fact when those who claim to have got it right retroactively brag about it. There is probably a bit of a selection bias there; we never hear about all the private polls that are wrong!"	"Sampling less affluent, younger, or minority voters remains a major challenge in research. Generally it is minimized in polling by low turnout among these groups, but in cases when they are mobilized (a la Bernie Sanders), researchers should take care to make sure they are capturing the right likely-voter population. "	"Barring a massive terror or conflict-related event, the only events that seem likely to notably move voters between now and the election are those that speak to candidate fundamentals. Further revelations about Trump's views towards women will not impact significantly, nor will those on Clinton's marriage. For an event to impact, it would have to somehow go to the core of their identity, rather than something that speaks to an already known/accepted aspect of their selves (even if upcoming October surprises seems ""worse"" or more dramatic than those that have already emerged)."	Same	Same with a slight edge towards demographics if done well. This will be a low-turnout election and modeling the likely-voter population is tricky. Doing so from a basis of demographics could be easier than narrowing down from polls.	No		Non-college-educated white women. This is a bloc that could make or break Trump.											Jon Cohen	SurveyMonkey						Florida	"Has it all -- Trump home, tough fight for Rubio, Hispanic voters, low-education whites, lots of electoral votes."																													John Anzalone	Anzalone Liszt Grove																																				
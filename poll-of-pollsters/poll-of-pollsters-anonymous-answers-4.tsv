"In light of Tuesday results, did election polls do well this year at depicting the electorate's views?"			Why do you say that?	Which polling organizations were particularly successful at projecting Tuesday's results?	Which polling organizations were particularly unsuccessful at projecting Tuesday's results?	"Which types of polls (i.e. live phone, IVR, online panel) were particularly successful at projecting Tuesday's results?"	"Which types of polls (i.e. live phone, IVR, online panel) were particularly unsuccessful at projecting Tuesday's results?"	Please expand on your answers above -- why do you think particular polling organizations and types were particularly successful or unsuccessful?	"What implications, if any, do you see from election polling's 2014 performance for the future of election polling?"	"Now that we know roughly how many seats Republicans will control in 2015, how many seats do you expect Republicans will control in the Senate in 2017?"	Why?	How have your last 24 hours gone? (i.e. Did you watch returns come in? Did you hear from clients? How did you react? How much sleep did you get? etc.)
Yes	No	Other (please specify)	Open-Ended Response	Open-Ended Response	Open-Ended Response	Open-Ended Response	Open-Ended Response	Open-Ended Response	Open-Ended Response	Open-Ended Response	Open-Ended Response	Open-Ended Response
Yes			Haven't gone over everyone else's; we were [100 percent accurate].	Haven't reviewed the individual performances so I can't answer the questions on this page yet.					"Alas, the large GOP victory will make pundits say the polls were all wrong. They weren't. Many, especially those with live interviewers, were very accurate in the states they were polling."	49	Presidential election brings out a more Democratic electorate.	"Great 24 hours. I am so proud of our team. We expect that our polling will be taken seriously. The results speak for themselves. Locally I personally consulted on six races in the Central Florida races: judge, statehouse, and school board. We won five of the races."
Yes			"Showed the anger with ""Washington"" -- but that translated into more anger with the President than with the Republicans. As with most midterms, young voters were no-shows."	No one single group	Most everyone who polled in the South.	Online and we wish we had just stuck to it. Our online was right on target but went unreleased.	Live phone		"I continue to think the problem in many, if not most, polls is that they decide a priori what the electorate will look like."	51	"More vulnerable Republican senators are up in 2016. Turnout in two years, a presidential-election year, is likely to favor the Democrats more than it did in this midterm year."	"I watched returns, spoke to media til 2 a.m., slept a bit, then did interviews, spoke to media partners, and started internal analysis and, oh yeah, had a cake to celebrate. I'm looking forward to some rest."
	No		We polled in 26 geographies. We embarrassed ourselves in just two of those 26 geographies. But that's two too many.	None	Too soon to have run analysis				My confidence has now increased. Some polls we did not even release because I was concerned about outliers and the negative press I usually get. I now have full confidence in my team and myself.	Haven't looked at this in detail yet.		I've had about 15 hours of sleep in the past four days.
	No		"Most polls systematically underestimated Republican performance and overestimated the impact of the ""Rising American Electorate"" [RAE]. (I still haven't had the time to hunt for numbers about whether this latter issue was because they overestimated RAE turnout, or RAE commitment to the Democrats, or some of each -- would be very interested to see a detailed analysis of that!) Polling in a few of the more progressive states -- like Connecticut, Massachusetts and Minnesota (not Maryland!) -- was more accurate. But in more purple states, there were some big misses."	Selzer & Company	None in particular jumped out at me. Mostly everyone.			"I get a sense that polls conducted by local firms (Selzer & Company, University of New Hampshire in New Hampshire, etc.) may have fared better. But it's just a sense, and I'm sure you guys have real numbers on it."	Not good. A lot of head-scratching.	No idea		"Since Pennsylvania was never a very close race, Election Day was basically uneventful."
	No			Selzer & Company	YouGov	Live	Online panel	Did not get who was really turning out. Panels may not accurately reflect older folks who do show up and younger ones who don't. The older and younger in panels may not be representative of the population.	Only bad things.	Somewhere between 10 and 90		"Watched less than expected, once it was clear there was a sweep."
		Some did and some didn't	"Kay Hagan's latest polling numbers looked pretty strong -- they didn't suggest she would lose by the margin she did. Greg Orman looked stronger than he turned out to be, too."	"Well, Selzer & Company was commonly called an outlier, but got it almost exactly."				"Actually, this is the kind of analysis I look to FiveThirtyEight to do. I have not been crunching these numbers."	"Pollsters will be more accurate in 2016 with an expanded electorate. The 2016 electorate will be more like pollsters thought the 2014 would look than the 2014 electorate actually was. And thus will ensue another ""unskewing"" battle from the right. Also, predictions based on ""fundamentals"" and prediction markets will garner more attention, at least from ""insiders."""	Whatever the 2014 number is (54 with GOP in Louisiana?) minus 3	"Maybe Democrats pick up Illinois, Pennsylvania and Wisconsinƒ if Hilary Clinton is running. GOP will be defending a lot of seats in 2016, but there's not much compelling reason right now to think that they won't hold most of them."	"Watched returns till 1:30 EDT. Would still like to know for sure who my Governor is (Connecticut). Five hours of sleep (could have been much worse!). We had a private client who wouldn't release a poll because the result was more stark (pro-GOP) than they could accept (it turned out to be accurate, slightly tilted pro-Democratic), and a public client who told us they were very happy, even though we probably could have been more accurate in that one. More than anything, I'm trying to figure out what to make of the idea (finally setting into my thick skull) that control of the House might be locked-in to 10-year cycles, based on statehouse races in each '0 year. That's not a polling issue (except that lots of pollsters will get extra work at local & state levels in 2020), but seems like a crucial issue of concern for our democracy."
									"The implications are the same after every election: Continue learning, continue experimenting, and continue working on your craft."			
							Online	RBS [Registration Based Sampling]! Time for academic pollsters to get serious about lists.	The never-ending struggle to determine who will vote balanced against the pressures of speed and cost. It won't get any easier.		This is not the kind of question I answer.	
								"I didn't follow individual polls in other states closely enough to talk about winners and losers nationally. In Pennsylvania, I think there were some real issues with several pollsters. Let's take the Harper Poll in Pennsylvania. In early September, it showed an 11-point [Democratic gubernatorial candidate Tom] Wolf lead and then a 10-point Wolf lead a week before the election. They will get credit for success with that last number, but no one had the race within 11 points in early September. That looks a bit like herding to me. The YouGov poll also makes me scratch my head: Their September poll showed Wolf +9 and their final poll showed Wolf +13. No other pollster showed the margin getting wider as Election Day approached. How will FiveThirtyEight assess these pollsters' performance? At the end, they were within the margin, but they clearly mischaracterized the nature of the race early on."			I haven't turned the page on this election yet.	
					"Zogby, Public Policy Polling"							